##### Topics
1. Kafka
2. Persistent Queues
3. Internals and terminology
4. Handling issues
#### 1. Kafka
Kafka is an open-source software platform for storing, processing, and analyzing **streaming data in real time**.

**Problem**
Facebook messenger -  Once a message has been sent and is stored in the database (both sender and receiver's machine), there might be some other processes that need to be carried out on the data, like notification. Notification can be through email, SMS and such. These can have more latency like 500ms for e.g. If we make the sender wait for all the processes to complete before returning success, it'd lead to latency.

Amazon - Once a order has been made, there can be many background processes like invoice generation, shipping, inventory updation, analytics updation, email, vendor notification etc. Here also we cannot make the user wait for all of these to complete before responding success.

In other words, after saving the message in machine, the other processes might need to be carried out **asynchronously**.

**Solution using messaging queues** 
Messaging queues are queues where multiple publishers can publish messages while multiple consumers can consume published messages. 
5. Persistent - Messaging queues are persistent and reliable. Once a data is stored you cannot lose it even if the machine goes down. Stored in hard disk with replicas.
6. Published messages are stored only for a limited period of time. 
7. Not truly FIFO. Lets say messages are sent as A->B and C->D. 

| A to B | A to B | C to D | A to B | C to D | A to B | A to B |
| ------ | ------ | ------ | ------ | ------ | ------ | ------ |
Here all messages of A to B and C to D are FIFO 100%. But order between As and Cs messages need not be in order.

A **Messaging Queue** is needed for:
8. **Asynchronous Processing** – Decouple components and let tasks be processed independently.
9. **Load Balancing** – Distribute workload across multiple consumers.
10. **Scalability** – Handle high traffic by scaling producers and consumers separately.
11. **Fault Tolerance** – Persist messages even if a service fails, ensuring reliability.
12. **Rate Limiting** – Prevent overwhelming downstream systems by controlling message flow.
13. **Microservices Communication** – Enable event-driven architecture in distributed systems.
14. **Delayed Processing** – Schedule tasks to execute at a later time.

#### 2. Persistent Queues
**Persistent Queue** is a type of messaging queue where the messages are stored in a way that ensures they are **not lost** even if the system crashes or restarts for a pre configured amount of time. In other words, it's a type of messaging queue with **durability**.

We know persistent queues work on the system of producer-consumer or publisher-subscriber. A unit can be both a producer and a subscriber as well.

- 'Topics' in messaging queue
In a **publish-subscribe (pub/sub) messaging system**, a **topic** represents a logical channel to which messages (events) are published. Subscribers interested in that topic will receive messages related to it.

For example, if **"like"** is defined as a topic, every **like event** (e.g., a user liking a post) will be published under this topic, and all subscribers to the "like" topic will receive notifications about those events.

e.g. In order system can add multiple topics into the queue like SIGN_UP, ORDER_PLACED, ORDER_CANCELLED etc to which email system can listen to.

#### 3. Terminologies
- **Producer** - Any service that may want to put an event into the queue (event generator).
- **Consumer** - Any service that may want to do something on a particular type of event
- Broker - A machine that is running Kafka

A production level queuing service (Kafka or any other) will also need to be distributed and not just be in one i.e. there might be multiple machines each having Kafka. The produced events will be pushed to these queues using a **Zookeeper** orchestrator. 

- Partition - Number of brokers an event of a particular topic will be sharded/divided into. 

In a distributed system, again we might need to have multiple brokers. Now, how do we divide the topics across multiple machines. 

15. Tag each topic to a specific machine. A machine can hold different topics but a topic will only belong to a machine.
**Problems**
- Multiple topics can have different loads. e.g. Like topic might have more load than Sign up topic as likes events are larger in number. 
- Topics an be large that it can exceed storage.
e.g. Broker 1 can have topics t1, t2, t3. Broker 2 can have t4, t5, t6 etc.
16. Split topics across multiple brokers. A broker can have multiple types of topics. A topic can also be split across multiple machines.
e.g. Broker 1 can have topics t1, t2, t3, t6. Broker 2 can have t2, t3, t4, t6 etc.

  In the above example, partition value of t1=1, t2=2, t3=2, t4=1, t6=2

![[Kafka-Architecture-01-01.webp]]

As an engineer, we analyze the loads of a particular topic and configure the Kafka to set this topic as having a partition of x. Kafka automatically internally handles it. We need not be bothered about which broker and all those complications.

#### 4. Handling Issues
1. Order of messages
 If a topic has only one partition, then order of events are always maintained. **The order within a partition is guaranteed to be maintained.** But when multiple partitions are present, the order might not be maintained. 

Lets say 3 messages A, B and C are sent in that order. A and C get pushed to partition 1 while B in partition 2. The consumer might consume A then C and then B.

- Sharding
Based on the fact that **The order within a partition is guaranteed to be maintained**, we can setup sharding using consistent hashing such that a series of messages will only go to one partition and thus the relative order will be maintained.

2. High load of a topic
A service e.g. emailService can be consuming multiple topics. A topic itself can be large in number, e.g. like topic. The consumer handling these can be faced with a large load. Therefore we need a distribute services as well. 

- Consumer Group
A consumer group is a set of machines. Each machine in one group will handle a particular topic. An event of a topic can be interested by multiple consumer groups. Kafka will ensure only one consumer of each interested consumer group will get the event. Kafka will also try to uniformly distribute the event across the machines in a group. We have to configure the group of each machine for that.

![[Pasted image 20250212212237.png]]

3. Death of broker
In order to provide protection against broker death, every topic will have a number of replicas. **Partition of a topic can be in the same machine, but replicas should always be in different machines.** Therefore, number of replicas <= number of brokers.

As replica number increases, latency will also increase.

- Internals and more topics on Kafka
https://docs.google.com/document/d/1FCi-xxi0HgR7he7Dsat2hsgiMFIiffSrLCecB6-BfT4/edit?tab=t.0#heading=h.fzwcs020kou5

___

