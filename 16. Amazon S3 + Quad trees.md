##### Topics
1. Amazon s3 and Storing Large Files
	1. Deciding chunk size
	2. HDFS
	3. Upload and download large files
2. Quad Trees

#### 1. Amazon S3 and Storing large files
Amazon S3(simple storage service) is a cloud based storage service for storing large and very large user generated files including images, audio, video, docs, ZIP, video files, logs, textures etc. which rarely change. 

Other examples of similar storage are Google Cloud Storage, Microsoft Azure Storage, Git LFS(large file storage).

Large files can take up to 50TB of storage. Such files cannot be easily stored in SQL or the noSQL dbs we've learned so far.

**Why not SQL and noSQL covered so far?**
- SQL is structured. Every column is of fixed size. This leads to either wastage of space or not enough space. 
- Large files in SQL can lead to data spanning across multiple blocks leading to increased latency.

The NoSQL like doc, column, key-value, graph etc. uses SSTables and LSM Trees which are also not optimized for storing these large files. 

So our task is to build a NoSQL db optimized for:
- **storing, retrieving, processing** large files of 50TB. 
- The storage should be **reliable and durable**.
- **downloading and uploading** these large files should be possible.
- to **perform Analytics** on these files.

**How to store a very large file?**
A 50 TB file will not fit in one server. Of course there are servers with more than 50TB storage, but it's not ideal. We'll have to split the file into chunks across multiple machines.

**What should the chunk size be?**
- RAM size - Even if the server has 1 TB of storage, we also need to take RAM size into account. Typically, the RAM size of a machine is around 1GB.
- Overhead with chunking - If we create N chunks, then while querying a file we also need to keep track of the machine where the chunk of the file is present. Using this we go to the server and access the chunk.

| file             | chunk_id | server_id |
| ---------------- | -------- | --------- |
| monthly_logs.txt | 1        | 3         |
|                  | 2        | 7         |
|                  | 3        | 1         |
|                  | ...      | ...       |
Each row can take, lets say 50b+8b+16b ~ 100b. 
If chunk size is 10Kb, then to store a 50TB files, number of chunks 
	= 50 x 10^12 b / 10 x 10^3 bytes = 5 x 10^9 chunks = 5 Billion chunks.
We have 5 Billion chunks so to store this info with each row taking 100b, we'd need 100b x 5 billion = 500 GB of storage.

**Conclusion**
- Chunk has to fit in a server
- Chunk has to fit in RAM
- Chunk size cannot be small
##### Deciding chunk size
Database providers do a lot of research and analysis and talks to the client and play around to find the optimal chunk size. 
**Typically a chunk size is a few hundred Mb, 128, 256 Mb**

##### Hadoop's Distributed File Storage (HDFS)
HDFS is another large file storage service

HDFS has multiple nodes to store the above
1. Data Node - chunks are stored
2. Name Node - Mapping(metadata) about chunks are stored as shown in the table below.

![[Screenshot 2025-02-19 184842 1.png]]

##### Reliability and Durability
Durability is present as we always write to disk.
Reliability is only achieved through replication.

If Name Node is lost the data itself is not lost, but we lose the mapping. **Therefore both Name and Data nodes need to be replicated.** Name node is arranged in a master-slave architecture. 
##### Consistency
❌ Eventually consistent - With this setup, if some data change happen in the file, stale data will be served at least for some time. Not allowed. 
✅ We need immediate consistency.

For immediate consistency, we set a **quorum**. In distributed systems, a "quorum" refers to the minimum number of nodes that must agree on a read or write operation for it to be considered valid, essentially acting as a majority vote to ensure data consistency. it'll be at least (x+1)/2 forming a majority where x is the total number of machines.

When a data is written, at least two machines will be written first before success. After than asynchronously the same will be written in more machines.

![[Screenshot 2025-02-19 184842z.png]]

**Replication does not happen in data node level, but on chunk level. Each chunk is replicated across multiple data nodes.**
##### Rack aware and Data center aware algorithms for further reliability
In a typical server room, each server will be stacked on top of each other as in the diagram below.

![[modern-server-stack-22528866.webp]]

Each segment is one server and here, a data node. This arrangement is called a **server rack**. In a server room there will be multiple server racks.

![[Pasted image 20250219191507.jpg]]

Each server rack will typically be connected to a **power supply** and a **router**.

**What happens when the power supply goes down?**
It's likely that when the power goes down, all server in the rack goes down. If the replicas of a chunk is stored in the same rack, there's a change to lose the chunk with power supply.

**Therefore, at least one replica of a chunk should be in a different server rack. This is based on a rack aware algorithm.**

Data centers can also go down together. **Therefore, we can extend the further by making sure that at least one replica should be in a different availability zone.**

##### Uploading and Downloading large files
- Chunking and Dechunking the data
We learned that S3 and HDFS are means through which large files are stored. From the client's perspective (client here is app server which requires the large file storage service here as in the diagram below), they don't care if the file is stored in multiple chunks, but rather they want the data to be as one single unit. All this chunking and de-chunking happens in the app server within the HDFS/S3.

![[Screenshot 2025-02-19 193804.png]]

- When the continuous stream of data reaches the App server in HDFS, it first checks with the Name Node to decide where should the next chunk be stored. 
- The Name Node returns two server ids, primary and secondary server ids. 
- Then the app server collects the data into a buffer of chunk size (128 Mb). 
- When the buffer is full, it'll flush the buffer into the Data Nodes.

```
int primary, secondary = getPrimarySecondaryDataNodes(file_id);
byte[] buffer = new byte[128*1024*1024];
int index=0;
while(byte b = getNextByte() != EndOFFile){
	buffer[index++] = b;
	if(index==chunk_size){
		AsyncSaveBufferDataIntoDataNode(buffer, primary, secondary);
		buffer = new byte[128*1024*1024];
		index = 0;
	}
}
if(index>0){ //if there are any half filled buffer.
	primary, secondary = getPrimarySecondaryDataNodes(file_id);
	AsyncSaveBufferDataIntoDataNode(buffer, primary, secondary);
	buffer = new byte[128*1024*1024];
}
```

##### Downloading
- HDFS Application server go to the Name Node and ask for all the metadata for that file. The NameNode responds with the addresses of the DataNodes that store replicas of each chunk of the file.
- The App server then connects to a DataNode that holds the first chunk and begins reading the data, streaming it into a local buffer.
- Once buffer starts receiving data, application server starts streaming it to the client.
- Once the app server has read the entirety of a chunk, it closes the connection to the current DataNode and connects to the next DataNode holding the subsequent chunk and loads this chunk into the buffer.
- Keep repeating this till all the chunks of the files has been streamed.
#### 2. Quad Trees
