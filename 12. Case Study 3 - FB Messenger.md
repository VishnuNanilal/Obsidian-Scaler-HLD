##### Topics
1. Interview simulation - FB Messenger
2. Idempotency

#### Interview simulation - FB Messenger
We know, for HLD of any system there are 5 steps
1. Functional requirements
2. Non functional requirements
3. Estimation of scele
4. API gathering
5. Design

#### FB Messenger interview simulation
1. Functional requirements / POC / Core features / MVP (**4-5mins**)
S. Messenger should have the functionality to send and receive messages.

Q. How about we go with only 1:1 chat or should group chat be supported?
A. Let's just go with 1:1 chat for this implementation

NOTE: A difference between FB Messenger and Whatsapp is that Whatsapp do not store messages on servers. That's why when we change mobiles, the data gets lost.

Q. Shall we support storing message history on servers?
A. Yes message storing in servers should be supported.

S. We would have to display recent messages.

Q. Shall we implement multimedia messages or only text messages?
A. We can keep it simple and go with only text messages for now.

Q. online, last online, read-unread?
A. No need for that in this interview.

2. Non-Functional requirements
- Consistency vs Availability
In a messenger app, consistency would mean preserving the order of messages. Deciding between C and A in messenger applications depends on the application. FB Messenger give importance to consistency.
(Slack and such group chat apps might give importance to availability. Reddit GC give importance to consistency which is might it lags and the order gets corrected at times).

- Consistency vs Latency
We'd want to build a system which is consistent with as low latency as possible. But if only one could be chosen, we'd choose consistency e.g. when an image is being sent the texts sent after it wont load until the image is delivered

3. Estimation of scale
 As you know, the starting user number estimation can be enquired from the interviewer.
Q. How many users are estimated to use the system per day?
A. Let's say there will be around 1 Billion users per day.

In estimation of scale, we need to quantify 3 things,
- Size of storage
- Req per second
- Type of requests (Read or Write heavy)

From these we'll figure out 
- Is sharding needed
- Type of requests

Let's say one person sends 50 messages. There will be 50Billion messages per day. Lets say one message has a schema of:

id: long (8b)
senderId: long (8b)
receiverId: long (8b)
time: **long** (8b)
content: String

NOTE: Time is typically stored as **epoch** time which is long. It represents the number of milliseconds since **1 JAN 1970 GMT+**

Lets say on an average each message content will be around 200 characters i.e. 200b. Therefore each message will be 8+8+8+8+200 ~ 250b. Therefore 250 x 50 x 10^9 bytes/day ~ 12500 x 10^9 b/day
Lets say we are provisioning it for 5 years. Therefore 5 x 365 x 12500 x 10^9 bytes ~ 25 x 10^ 12 ~ 25PB

We have estimated the storage needed. We need sharding.

On a one on one chat, we normally sends a message which will be typically read once. So read : write is 1:1 => System is both read and write heavy. (In a group chat, one message written will be read multiple types. It'd be read heavy normally)

4. API gathering
- sendMessage(senderId, receiverId, content)
We are not sending the time from front end because then users might be able to hack the time to change it etc. 

- getConversationList(userId, offset, limit)
Why offset, limit? (**Tracxn interview question**)
Should we send all the conversations of a user in one go? No. Here we'd have to implement pagination. From **offset** we load **limit** number of conversations.

- getMessages(userId, otherId, offset, limit) or getMessages(conversationId, offset, limit)

___
#### 2. Idempotency
 In a request response cycle, when a client sends a request to the server, the server response with an acknowledgement even before the request is processed. This indicates that the request was received. If the request was not received, no acknowledgement will be send back in which case the request will be resent by the client. But some cases the request will be received but the acknowledgement fails to reach the client. In this case the client sends another request leading to two successful request instead of one. In messenger app, this would be registering same message twice in server which is an error.

Therefore we need a way for server to be able to reject a duplicate request. But how do we identify two messages to be the same. We cannot rely on the content for that. Therefore whenever a message is sent from client, we need to include an unique_id. Inorder to generate a unique id we need an input. What can this input be?

At the same time, 
- two people can send the same content => content alone wont do.
- a person can send same message from two devices => sender id alone wont do
- two messages to the same receiver can be send =>receiverId alone wont do

Therefore we need a combination of timestamp, senderId, receiverId, deviceId. This is called Idempotency.

**Idempotency is this way by which we uniquely identify a message to ensure that no duplicate message will be sent to the server.**

___

5. Design
We understood there will be sendMessage(), getConversationList(), getMessage() APIs. These 3 APIs would work on a Messages Table. 
We'd also need to store around 25PB of data. 

We'd need sharding.

- Sharding key
What should be the sharding key?
Sharding key should be based on uniform load distribution and ideally should reduce querying on multiple machines for a request. Timestamp is a bad reason for uneven distribution of load.

**Sharding by conversation id**
All messages of a particular conversation id will be in one machine. Both sendMessage() and getMessages() will only query one machine. BUT, getConversationList() will have to query multiple machines.

**shard by conversation id but keep another database for Conversations sharded by userId**
Create a new database where you have a conversation Table where we store the complete conversation of a user in a list. This database will be sharded by userId.

Conversations

| userId | List of conversation |
| ------ | -------------------- |
| 100    | [conv1, conv2...]    |
**getMessages()** will only need to query one machine.
**sendMessage()** will query the Messages Table database, and will have to update Conversation of the sender and reciever in Conversations Table. As a result we might have to query 3 messages.
**getConversation()** will only need to query one machine

**shard by user Id**
Here all messages either sent or received by a user will be in one machine. 

**getMessages()** will only query on one machine
sendMessages() will query on 2 machines
getConversationList() will query on 1 machine

The only downside is that we may have to keep copies of one message on 2 machines to cater to user 1(sender) and user 2(receiver). Low latency is more important than storage saving.

- **Failure Situation where we writing to two database machines**
As we've seen sendMessage() API might query on two machines sharded by user Id. From the sender and recieverId we resolve the hashes of the machines and process on them. 

```java
sendMessage(senderId, receiverId, message) {
    senderShard = getShard(senderId);
    receiverShard = getShard(receiverId);

    senderDB = getDB(senderShard);
    receiverDB = getDB(receiverShard);

    senderDB.storeMessage(message);
    receiverDB.storeMessage(message);
}
```

These processes on DB1(machine where sender messages are present) and DB2(machine where receiver messages are present) can fail.

**DB1 success, DB2 success**. No data inconsistency. This is fine.
**DB1 fails, DB2 fails**. No data inconsistency. 
**DB1 success, DB2 fails**. Data inconsistency. Sender finds the data as sent. Receiver will not.
**DB1 fails, DB2 success**. (Here we write to DB2 first before DB1). Sender might find it as not sent, but receiver has received it. Sender is already aware of the data, so even if they see it as not sent, its less problematic than sender believing the data was received while receiver not.

___
