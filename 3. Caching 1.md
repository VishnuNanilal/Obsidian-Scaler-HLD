##### Topics
1. Caching
	1. Client/In Browser
	2. CDN
	3. Local Caching
	4. Global Caching
2. Problems with caching
3. Cache Invalidation strategy
	1. Time to live (TTL)
4. Cache eviction strategy

- Basic design of a scalable backend (Revision)
A scalable backend consists of multiple application servers for business logic and database machine system for storage. Each database machine is not directly integrated to a server, but are loosely coupled to the application server system. Even if one server goes down, the rest of the servers can still work with the database without any redistribution of data. Both servers and database can scale independently.

##### Gateway
Gateway is a single machine which acts like a gateway to which all requests are received first. Its the single point of contact. It also acts like a load balancer, balancing the load across all the application servers.

##### Stateful and Stateless App server
Application server layer can be both stateful and stateless.

- stateless
LB can forward to any server to process. Here we can use round robin/weighted round robin.

e.g. A calculator machine. No server stores any state, instead simply stores the calculation logic and any machine can be used to process a request. 

A lot of real world design is based on stateless due to the above advantage.

- stateful
 When continuous session awareness is required, e.g. Banking, e-Commerce or when data processing is required for every request, e.g. ChatGPT LLMs, using stateless app servers can cause latency. This is why in some cases we may have to go with stateful servers. In such a design, the LB would need to use Consistent Hashing instead of Round Robin.

#### 1. Caching
Storing a data as a copy in a place from where it can be read quickly.

- Client side/ In browser caching
Client-side caching refers to storing data on the client (e.g., browser, mobile app, or other front-end systems) to reduce the need for repeated requests to the server. By caching data locally, client-side caching improves performance, reduces server load, and enhances the user experience by providing faster access to frequently used data.

- CDN caching
Content Delivery Network(CDN)
A **Content Delivery Network (CDN)** is a distributed network of servers that work together to deliver large data to users more efficiently. 

A user requests a resource to the main server. Instead of sending back the data, it sends back reroutes to the CDN, which responds with the requested resource.  If the content is not cached (a cache miss), the edge server fetches it from the origin server, caches it, and serves it to the user. By caching content in servers located geographically closer to users, CDNs improve website performance, reduce latency, and ensure high availability.

- App server/Local caching
As explained earlier, when a stateful application server caches data within itself, it's an app server caching.

- Global caching
Global machines are specialized machines that exists in the backend outside both app servers and databases, whose only purpose is to store caches.

![[Screenshot 2025-01-16 191436.png]]

#### 2. Problems with caching
1. Cache size is limited. Unused data might need to be removed
2. Cache is just a copy and is not the ultimate source of truth. Cache data might be stale.
	e.g. The likes you see on FB might not always be the correct like count. It might have been fetched from a stale cache.
3. Cache is volatile and will be lost with lose of power.

In order to avoid these problems, we have cache invalidation and eviction.
#### 3. Cache Invalidation strategy
- **Time to Live (TTL)**
Whenever a cache data is saved, a TTL is set. Once TTL is over, the cache is invalidated. 
If the TTL is set short, the use of cache is reduced. If it's long, chances of data inconsistency is higher.

**Advantages**
- Keeps freeing up the cache
- Cache will not remain stale for a long time

#### 4. Cache Eviction strategy
- ***FIFO*** (First In First Out)
- ***LRU*** (Least Recently Used)
- MRU (Most Recently Used)
- LIFO (Last in First Out)